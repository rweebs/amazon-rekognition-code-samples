{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face Detection using Amazon Rekognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "This notebook provides a walkthrough of [detect face recognition API](https://docs.aws.amazon.com/rekognition/latest/dg/faces-detect-images.html) in Amazon Rekognition. You can see face details include a bounding box of the face, a confidence value (that the bounding box contains a face), and a fixed set of attributes such as facial landmarks (for example, coordinates of eye and mouth), presence of beard, sunglasses, and so on. \n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise Notebook\n",
    "import boto3\n",
    "from IPython.display import HTML, display, Image as IImage\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Curent AWS Region. Use this to choose corresponding S3 bucket with sample content\n",
    "\n",
    "mySession = boto3.session.Session()\n",
    "awsRegion = mySession.region_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init clients\n",
    "rekognition = boto3.client('rekognition')\n",
    "s3 = boto3.client('s3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create temporary directory\n",
    "# This directory is not needed to call Rekognition APIs.\n",
    "# We will only use this directory to download images from S3 bucket and draw bounding boxes\n",
    "# around recognized celebrities to show them here in the notebook.\n",
    "\n",
    "!mkdir m1tmp\n",
    "tempFolder = 'm1tmp/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Face Detection\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagePath = \"./static/hat-detection.png\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img=Image.open(imagePath)\n",
    "display(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Call Rekognition to recognize faces in the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call Amazon Rekognition to recognize faces in the image\n",
    "with open(imagePath, 'rb') as image:\n",
    "# Todo-1 Assign rekognition detect moderation labels to detectModerationLabel variable with byte data from image.read()\n",
    "# resource https://boto3.amazonaws.com/v1/documentation/api/1.9.42/reference/services/rekognition.html#Rekognition.Client.detect_faces\n",
    "    faceDetectsResponse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Review the raw JSON reponse from Rekognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show JSON response returned by Rekognition Celebrity Recognition API\n",
    "# In the JSON response below, you will see CelebrityFaces which contains information about recognized celebrities.\n",
    "# For each recognized celebrity, you will see information like Name, Id, Urls and additional information about \n",
    "# their facial attributes.\n",
    "\n",
    "display(faceDetectsResponse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Show image with bounding boxes around recognized faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function that will display image with bounded boxes around recognized faces\n",
    "# We will call this function in next step\n",
    "import io\n",
    "\n",
    "def drawBoundingBoxes (boxes, image):\n",
    "    # blue, green, red, grey\n",
    "    colors = ((255,255,255),(255,255,255),(76,182,252),(52,194,123))\n",
    "\n",
    "    # Draws BB on Image\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    width, height = image.size\n",
    "    col = 0\n",
    "    maxcol = len(colors)\n",
    "    line= 3\n",
    "    for box in boxes:\n",
    "        left = width * box['Left']\n",
    "        top = height * box['Top']\n",
    "        width = width * box['Width']\n",
    "        height = height * box['Height']\n",
    "    \n",
    "        points = (\n",
    "            (left,top),\n",
    "            (left + width, top),\n",
    "            (left + width, top + height),\n",
    "            (left , top + height),\n",
    "            (left, top)\n",
    "        )\n",
    "        draw.line(points, fill='#00d400', width=2)\n",
    "        \n",
    "    display(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract bounding box information from JSON response above and display image with bounding boxes around faces.\n",
    "\n",
    "boxes = []\n",
    "faces = faceDetectsResponse['FaceDetails']\n",
    "for face in faces:\n",
    "    boxes.append (face['BoundingBox'])\n",
    "    \n",
    "drawBoundingBoxes(boxes,img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try with your own face\n",
    "- Upload your image to the static folder in this directory\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Todo-2 assign imagePath with your face image\n",
    "imagePath = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img=Image.open(imagePath)\n",
    "display(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Call Rekognition to recognize faces in the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call Amazon Rekognition to recognize faces in the image\n",
    "with open(imagePath, 'rb') as image:\n",
    "    faceDetectsResponse = rekognition.detect_faces(Image={'Bytes': image.read()})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Review the raw JSON reponse from Rekognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show JSON response returned by Rekognition Celebrity Recognition API\n",
    "# In the JSON response below, you will see CelebrityFaces which contains information about recognized celebrities.\n",
    "# For each recognized celebrity, you will see information like Name, Id, Urls and additional information about \n",
    "# their facial attributes.\n",
    "\n",
    "display(faceDetectsResponse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Show image with bounding boxes around recognized faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function that will display image with bounded boxes around recognized faces\n",
    "# We will call this function in next step\n",
    "import io\n",
    "\n",
    "def drawBoundingBoxes (boxes, image):\n",
    "    # blue, green, red, grey\n",
    "    colors = ((255,255,255),(255,255,255),(76,182,252),(52,194,123))\n",
    "\n",
    "    # Draws BB on Image\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    width, height = image.size\n",
    "    col = 0\n",
    "    maxcol = len(colors)\n",
    "    line= 3\n",
    "    for box in boxes:\n",
    "        left = width * box['Left']\n",
    "        top = height * box['Top']\n",
    "        width = width * box['Width']\n",
    "        height = height * box['Height']\n",
    "    \n",
    "        points = (\n",
    "            (left,top),\n",
    "            (left + width, top),\n",
    "            (left + width, top + height),\n",
    "            (left , top + height),\n",
    "            (left, top)\n",
    "        )\n",
    "        draw.line(points, fill='#00d400', width=2)\n",
    "        \n",
    "    display(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract bounding box information from JSON response above and display image with bounding boxes around faces.\n",
    "\n",
    "boxes = []\n",
    "faces = faceDetectsResponse['FaceDetails']\n",
    "for face in faces:\n",
    "    boxes.append (face['BoundingBox'])\n",
    "    \n",
    "drawBoundingBoxes(boxes,img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### References\n",
    "- https://docs.aws.amazon.com/rekognition/latest/dg/images-bytes.html\n",
    "- https://boto3.amazonaws.com/v1/documentation/api/1.9.42/reference/services/rekognition.html#Rekognition.Client.detect_faces\n",
    "- https://docs.aws.amazon.com/rekognition/latest/APIReference/API_DetectFaces.html\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recognize faces in video\n",
    " Face recognition in video is an async operation. \n",
    "https://docs.aws.amazon.com/rekognition/latest/dg/API_StartFaceDetection.html. \n",
    "\n",
    "- First we start a face detection job which returns a Job Id.\n",
    "- We can then call `get_face_detection` to get the job status and after job is complete, we can get object metadata.\n",
    "- In production use cases, you would usually use StepFunction or SNS topic to get notified when job is complete.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Todo-3 download object-detection.mov file and upload to your s3, assign bucketName with your own bucket and videoName with the object key\n",
    "videoName = \"\"\n",
    "bucketName = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Call Rekognition to start a job for object detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start video label recognition job\n",
    "startFaceDetection = rekognition.start_face_detection(\n",
    "    Video={\n",
    "        'S3Object': {\n",
    "            'Bucket': bucketName,\n",
    "            'Name': videoName,\n",
    "        }\n",
    "    },\n",
    ")\n",
    "\n",
    "labelsJobId = startFaceDetection['JobId']\n",
    "display(\"Job Id: {0}\".format(labelsJobId))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wait for object detection job to complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wait for object detection job to complete\n",
    "# In production use cases, you would usually use StepFunction or SNS topic to get notified when job is complete.\n",
    "getObjectDetection = rekognition.get_face_detection(\n",
    "    JobId=labelsJobId\n",
    ")\n",
    "\n",
    "while(getObjectDetection['JobStatus'] == 'IN_PROGRESS'):\n",
    "    time.sleep(5)\n",
    "    print('.', end='')\n",
    " \n",
    "    getObjectDetection = rekognition.get_face_detection(\n",
    "    JobId=labelsJobId)\n",
    "    \n",
    "display(getObjectDetection['JobStatus'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Review raw JSON reponse from Rekognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show JSON response returned by Rekognition Object Detection API\n",
    "# In the JSON response below, you will see list of detected objects and activities.\n",
    "# For each detected object, you will see information like Timestamp\n",
    "\n",
    "display(getObjectDetection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Show video in the player"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Show video in a player\n",
    "\n",
    "s3VideoUrl = s3.generate_presigned_url('get_object', Params={'Bucket': bucketName, 'Key': videoName})\n",
    "\n",
    "videoTag = \"<video controls='controls' autoplay width='640' height='360' name='Video' src='{0}'></video>\".format(s3VideoUrl)\n",
    "\n",
    "videoui = \"<table><tr><td style='vertical-align: top'>{}</td></tr></table>\".format(videoTag)\n",
    "\n",
    "display(HTML(videoui))"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:ap-southeast-1:492261229750:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
